{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vilniustransportOpenDataAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdvardasDlugauskas/VT-atvir-duomen-analiz-/blob/master/vilniustransportOpenDataAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1i2UI4BwtRU",
        "colab_type": "text"
      },
      "source": [
        "# **Importing all libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyQ2VtgOwoa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir, path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch import nn, optim, autograd, FloatTensor, manual_seed, randperm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn import model_selection, preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5njEcfYqp4x",
        "colab_type": "text"
      },
      "source": [
        "# **Importing data from csv files (pd.read_csv)**\n",
        "\n",
        "add csv files which names is shown in this section\n",
        "\n",
        "Need to have a `VTDeepLearn/data/` folder with CSV data files in your Google Drive (get them from here: [Mega link](https://mega.nz/file/eAQB2aKQ#vJj5EapA8RUzwS_YRnKTnRsMXBNfb-eXOGIkRitoADI))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcF1JGkFspEZ",
        "colab_type": "code",
        "outputId": "bad223f1-de32-47da-c347-78ca839ab552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctApmFTbpsAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_FOLDER_PATH = \"/content/drive/My Drive/VTDeepLearn/data\"\n",
        "file_names = listdir(DATA_FOLDER_PATH)[:12]\n",
        "dataframes = [pd.read_csv(path.join(DATA_FOLDER_PATH, file)) for file in file_names]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r1_YfCX--LS",
        "colab_type": "text"
      },
      "source": [
        "**Import stops names and Ids**\n",
        "\n",
        "(Add folder to VTDeepLearn StopsInfo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcdMEqyF99Dy",
        "colab_type": "code",
        "outputId": "4a8c8b04-387f-4c92-d0cd-e98e8356c301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "STOPS_DATA_FOLDER_PATH = \"/content/drive/My Drive/VTDeepLearn/StopsInfo\"\n",
        "stops_file_names = listdir(STOPS_DATA_FOLDER_PATH)[:1]\n",
        "stopsInfoList =  [pd.read_csv(path.join(STOPS_DATA_FOLDER_PATH, file)) for file in stops_file_names]\n",
        "stopsInfoData = pd.concat(stopsInfoList).reset_index(drop=True)\n",
        "print(stopsInfoData)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      id                    name\n",
            "0      1                „Sparta“\n",
            "1      2             Naujininkai\n",
            "2      3   Dariaus ir Girėno st.\n",
            "3      4                  Stotis\n",
            "4      5               Prūsų st.\n",
            "..   ...                     ...\n",
            "659  660      Stepono Kairio st.\n",
            "660  661              Metropolis\n",
            "661  662            Vokiečių st.\n",
            "662  663          Balsių mokykla\n",
            "663  664  Žaliojo Visalaukio st.\n",
            "\n",
            "[664 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2z1VLhGvI5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = pd.concat(dataframes).reset_index(drop=True)\n",
        "# TODO: all_data.max for normalization\n",
        "all_data['IsHoliday'] = all_data['IsHoliday'].replace({False: 0, True: 1})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VXQp8CTJj8U",
        "colab_type": "text"
      },
      "source": [
        "Replace all stops names with ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEv5QPrM_Xvn",
        "colab_type": "code",
        "outputId": "63d73c57-3aa8-423d-c02d-c5a94a9f7f7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "for index, stopInfo in stopsInfoData.iterrows() :\n",
        "  all_data = all_data.replace(to_replace = stopInfo['name'], \n",
        "                 value = stopInfo['id']) \n",
        "\n",
        "print(all_data['EndStop'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        172\n",
            "1          5\n",
            "2        172\n",
            "3        172\n",
            "4        172\n",
            "        ... \n",
            "90757    528\n",
            "90758    402\n",
            "90759    528\n",
            "90760    312\n",
            "90761    348\n",
            "Name: EndStop, Length: 90762, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI9yzENhNCuM",
        "colab_type": "text"
      },
      "source": [
        "Classify according to bus type\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00zYhyfSNB53",
        "colab_type": "code",
        "outputId": "6a2ffe10-236d-4feb-8087-59de8295c353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "busDummy = pd.get_dummies(all_data['TransportType'])\n",
        "all_data = pd.concat([all_data,busDummy],axis=1)\n",
        "print(busDummy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       BUS  EXP_BUS  TROL\n",
            "0        1        0     0\n",
            "1        1        0     0\n",
            "2        1        0     0\n",
            "3        1        0     0\n",
            "4        1        0     0\n",
            "...    ...      ...   ...\n",
            "90757    0        0     1\n",
            "90758    0        0     1\n",
            "90759    0        0     1\n",
            "90760    0        0     1\n",
            "90761    0        0     1\n",
            "\n",
            "[90762 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSCjKhY_d4Zd",
        "colab_type": "text"
      },
      "source": [
        "classify according to bus number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGc07-8td3hS",
        "colab_type": "code",
        "outputId": "969e7005-ff21-4ca7-b346-74a73a50772f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "busNumberDummy = pd.get_dummies(all_data['Number'])\n",
        "all_data = pd.concat([all_data,busNumberDummy],axis=1)\n",
        "print(busNumberDummy)\n",
        "\n",
        "[1, 1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       1  10  101N  102N  103N  104N  105N  11  ...  74  75  76  78  8  82  87  9\n",
            "0      1   0     0     0     0     0     0   0  ...   0   0   0   0  0   0   0  0\n",
            "1      1   0     0     0     0     0     0   0  ...   0   0   0   0  0   0   0  0\n",
            "2      1   0     0     0     0     0     0   0  ...   0   0   0   0  0   0   0  0\n",
            "3      1   0     0     0     0     0     0   0  ...   0   0   0   0  0   0   0  0\n",
            "4      1   0     0     0     0     0     0   0  ...   0   0   0   0  0   0   0  0\n",
            "...   ..  ..   ...   ...   ...   ...   ...  ..  ...  ..  ..  ..  .. ..  ..  .. ..\n",
            "90757  0   0     0     0     0     0     0   0  ...   0   0   0   0  0   0   0  1\n",
            "90758  0   0     0     0     0     0     0   0  ...   0   0   0   0  0   0   0  1\n",
            "90759  0   0     0     0     0     0     0   0  ...   0   0   0   0  0   0   0  1\n",
            "90760  0   0     0     0     0     0     0   0  ...   0   0   0   0  0   0   0  1\n",
            "90761  0   0     0     0     0     0     0   0  ...   0   0   0   0  0   0   0  1\n",
            "\n",
            "[90762 rows x 84 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMPBTfiXO4lk",
        "colab_type": "code",
        "outputId": "f1fd742d-c1b1-4ce9-e5a8-dd6fcd37ca72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "print(all_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      TransportType Number  StartStop  EndStop  ...  IsHoliday  BUS  EXP_BUS  TROL\n",
            "0               BUS      1          8      172  ...          0    1        0     0\n",
            "1               BUS      1          9        5  ...          0    1        0     0\n",
            "2               BUS      1          8      172  ...          0    1        0     0\n",
            "3               BUS      1          8      172  ...          0    1        0     0\n",
            "4               BUS      1          5      172  ...          0    1        0     0\n",
            "...             ...    ...        ...      ...  ...        ...  ...      ...   ...\n",
            "90757          TROL      9        309      528  ...          0    0        0     1\n",
            "90758          TROL      9        312      402  ...          0    0        0     1\n",
            "90759          TROL      9        349      528  ...          0    0        0     1\n",
            "90760          TROL      9        537      312  ...          0    0        0     1\n",
            "90761          TROL      9         82      348  ...          0    0        0     1\n",
            "\n",
            "[90762 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2N_-86Qw0cY",
        "colab_type": "code",
        "outputId": "658c0c84-fc41-4f28-ad53-3f71dceacdbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "test_data = all_data[['ScheduledDeparture', 'ActualDeparture', 'ScheduledArrival', 'ActualArrival', 'IsHoliday']]\n",
        "for column in test_data.drop(columns=['IsHoliday']):\n",
        "    test_data.loc[:,column] = test_data.loc[:,column] / 1640"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdv9azenw5FR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_np, test_x_np, train_y_np, test_y_np = model_selection.train_test_split(test_data.drop(columns=['ActualArrival']).to_numpy(), test_data['ActualArrival'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "train_x, test_x = map(lambda x: autograd.Variable(FloatTensor(x), requires_grad=True), [train_x_np, test_x_np])\n",
        "train_y, test_y = map(lambda x: autograd.Variable(FloatTensor(x)), [train_y_np, test_y_np])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwtJm8ejwNit",
        "colab_type": "text"
      },
      "source": [
        "**Alernative Test methods:**\n",
        "\n",
        "Trying predict according to bus latency \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmLkUqACP3-A",
        "colab_type": "code",
        "outputId": "61a44171-97fd-4e9a-fd7e-b79a6bf86162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "new_test_data = all_data;\n",
        "print(new_test_data);\n",
        "saveActualArrival = new_test_data['ActualArrival'] / 1440\n",
        "saveScheduledArrival = new_test_data['ScheduledDeparture'] / 1440\n",
        "new_test_data = new_test_data.drop(columns=['TransportType'])\n",
        "new_test_data = new_test_data.drop(columns=['Number']) #later try classify\n",
        "new_test_data['StartStop'] = new_test_data['StartStop'] / 1440\n",
        "new_test_data['EndStop'] = new_test_data['EndStop'] / 1440\n",
        "new_test_data['ScheduledDeparture'] = (new_test_data['ScheduledDeparture'] - new_test_data['ScheduledDeparture'] % 30) / 1440\n",
        "new_test_data['ActualDeparture'] = (new_test_data['ActualDeparture'] - new_test_data['ActualDeparture'] % 30) / 1440\n",
        "new_test_data['ScheduledArrival'] = (new_test_data['ScheduledArrival'] - new_test_data['ScheduledArrival'] % 30) / 1440\n",
        "new_test_data['ActualArrival'] = (new_test_data['ActualArrival'] - new_test_data['ActualArrival'] % 30) / 1440\n",
        "\n",
        "\n",
        "1 -> 59\n",
        "29 -> 31\n",
        "\n",
        "0 -> 30\n",
        "\n",
        "\n",
        "1440 -> 48 classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      TransportType Number  StartStop  EndStop  ...  8  82  87  9\n",
            "0               BUS      1          8      172  ...  0   0   0  0\n",
            "1               BUS      1          9        5  ...  0   0   0  0\n",
            "2               BUS      1          8      172  ...  0   0   0  0\n",
            "3               BUS      1          8      172  ...  0   0   0  0\n",
            "4               BUS      1          5      172  ...  0   0   0  0\n",
            "...             ...    ...        ...      ...  ... ..  ..  .. ..\n",
            "90757          TROL      9        309      528  ...  0   0   0  1\n",
            "90758          TROL      9        312      402  ...  0   0   0  1\n",
            "90759          TROL      9        349      528  ...  0   0   0  1\n",
            "90760          TROL      9        537      312  ...  0   0   0  1\n",
            "90761          TROL      9         82      348  ...  0   0   0  1\n",
            "\n",
            "[90762 rows x 96 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUc5LlUzvEzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "somey = saveActualArrival.to_numpy() - saveScheduledArrival.to_numpy()\n",
        "\n",
        "\n",
        "train_x_np, test_x_np, train_y_np, test_y_np = model_selection.train_test_split(new_test_data.drop(columns=['ActualArrival']).to_numpy(), somey.reshape(-1, 1))\n",
        "\n",
        "train_x, test_x = map(lambda x: autograd.Variable(FloatTensor(x), requires_grad=True), [train_x_np, test_x_np])\n",
        "train_y, test_y = map(lambda x: autograd.Variable(FloatTensor(x)), [train_y_np, test_y_np])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtZFZHXnUaZG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgHKAH2BvZmw",
        "colab_type": "code",
        "outputId": "a2cde392-aa42-4fd7-985d-2f5e8719c687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "print(new_test_data.drop(columns=['ActualArrival']).to_numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00555556 0.11944444 0.20833333 ... 0.         0.         0.        ]\n",
            " [0.00625    0.00347222 0.22916667 ... 0.         0.         0.        ]\n",
            " [0.00555556 0.11944444 0.25       ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.24236111 0.36666667 0.70833333 ... 0.         0.         1.        ]\n",
            " [0.37291667 0.21666667 0.75       ... 0.         0.         1.        ]\n",
            " [0.05694444 0.24166667 0.77083333 ... 0.         0.         1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c2TmAvXwUff",
        "colab_type": "text"
      },
      "source": [
        "end of test methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgVKyPWIz3ZM",
        "colab_type": "code",
        "outputId": "3e826056-b67b-4807-d0d4-91ecbe153e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "manual_seed(3)\n",
        "\n",
        "net = nn.Sequential(\n",
        "        nn.Linear(93, 20),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(20, 10),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(10, 1),\n",
        "    )\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.2)\n",
        "loss_func = nn.MSELoss()\n",
        "batch_size = 500_000\n",
        "\n",
        "val_loss_history = []\n",
        "train_loss_history = []\n",
        "\n",
        "for epoch in range(5000):\n",
        "    net.train()\n",
        "\n",
        "    data_len = train_x.size()[0];\n",
        "    permutation = randperm(data_len)\n",
        "\n",
        "    epoch_losses = []\n",
        "    for batch_i in range(0, data_len, batch_size):\n",
        "        \n",
        "\n",
        "        indices = permutation[batch_i:batch_i+batch_size]\n",
        "        batch_x, batch_y = train_x[indices], train_y[indices]\n",
        "\n",
        "        outputs = net(batch_x)\n",
        "        loss = loss_func(outputs, batch_y)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_losses.append(loss.item())\n",
        "    \n",
        "    train_loss_history.append(np.mean(epoch_losses))\n",
        "\n",
        "    net.eval()\n",
        "    y_hat = net(test_x) \n",
        "\n",
        "    val_loss = loss_func(y_hat, test_y).item()\n",
        "    val_loss_history.append(val_loss)\n",
        "\n",
        "    if not epoch % 10:\n",
        "        print(f\"Epoch: {epoch}, loss: {val_loss}\")\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, loss: 0.0066184233874082565\n",
            "Epoch: 10, loss: 0.0002354859170736745\n",
            "Epoch: 20, loss: 0.00022707346943207085\n",
            "Epoch: 30, loss: 0.00021927400666754693\n",
            "Epoch: 40, loss: 0.00021200104674790055\n",
            "Epoch: 50, loss: 0.00020519233657978475\n",
            "Epoch: 60, loss: 0.00019881232583429664\n",
            "Epoch: 70, loss: 0.00019281345885246992\n",
            "Epoch: 80, loss: 0.00018717160855885595\n",
            "Epoch: 90, loss: 0.0001818692107917741\n",
            "Epoch: 100, loss: 0.00017688154184725136\n",
            "Epoch: 110, loss: 0.00017220476001966745\n",
            "Epoch: 120, loss: 0.00016782064631115645\n",
            "Epoch: 130, loss: 0.0001637070527067408\n",
            "Epoch: 140, loss: 0.0001598482340341434\n",
            "Epoch: 150, loss: 0.00015621971397195011\n",
            "Epoch: 160, loss: 0.00015280245861504227\n",
            "Epoch: 170, loss: 0.00014957814710214734\n",
            "Epoch: 180, loss: 0.0001465297391405329\n",
            "Epoch: 190, loss: 0.00014365205424837768\n",
            "Epoch: 200, loss: 0.00014093196659814566\n",
            "Epoch: 210, loss: 0.0001383501512464136\n",
            "Epoch: 220, loss: 0.00013588905858341604\n",
            "Epoch: 230, loss: 0.00013353623216971755\n",
            "Epoch: 240, loss: 0.0001312709937337786\n",
            "Epoch: 250, loss: 0.00012908651842735708\n",
            "Epoch: 260, loss: 0.00012697641795966774\n",
            "Epoch: 270, loss: 0.0001249272027052939\n",
            "Epoch: 280, loss: 0.0001229379267897457\n",
            "Epoch: 290, loss: 0.00012100855383323506\n",
            "Epoch: 300, loss: 0.00011913509661098942\n",
            "Epoch: 310, loss: 0.00011730846745194867\n",
            "Epoch: 320, loss: 0.00011552549403859302\n",
            "Epoch: 330, loss: 0.00011378277122275904\n",
            "Epoch: 340, loss: 0.00011208399519091472\n",
            "Epoch: 350, loss: 0.00011043750419048592\n",
            "Epoch: 360, loss: 0.00010883674258366227\n",
            "Epoch: 370, loss: 0.00010727946209954098\n",
            "Epoch: 380, loss: 0.00010576231579761952\n",
            "Epoch: 390, loss: 0.00010428163659526035\n",
            "Epoch: 400, loss: 0.0001028364131343551\n",
            "Epoch: 410, loss: 0.00010143524559680372\n",
            "Epoch: 420, loss: 0.00010008768731495366\n",
            "Epoch: 430, loss: 9.878710261546075e-05\n",
            "Epoch: 440, loss: 9.753279300639406e-05\n",
            "Epoch: 450, loss: 9.632969158701599e-05\n",
            "Epoch: 460, loss: 9.517955186311156e-05\n",
            "Epoch: 470, loss: 9.407768811797723e-05\n",
            "Epoch: 480, loss: 9.301871614297852e-05\n",
            "Epoch: 490, loss: 9.200189379043877e-05\n",
            "Epoch: 500, loss: 9.102743933908641e-05\n",
            "Epoch: 510, loss: 9.009097266243771e-05\n",
            "Epoch: 520, loss: 8.91897507244721e-05\n",
            "Epoch: 530, loss: 8.832092134980485e-05\n",
            "Epoch: 540, loss: 8.747864922042936e-05\n",
            "Epoch: 550, loss: 8.666361100040376e-05\n",
            "Epoch: 560, loss: 8.58765488374047e-05\n",
            "Epoch: 570, loss: 8.511629130225629e-05\n",
            "Epoch: 580, loss: 8.438155055046082e-05\n",
            "Epoch: 590, loss: 8.366892143385485e-05\n",
            "Epoch: 600, loss: 8.297699969261885e-05\n",
            "Epoch: 610, loss: 8.230376988649368e-05\n",
            "Epoch: 620, loss: 8.1648126069922e-05\n",
            "Epoch: 630, loss: 8.100819104583934e-05\n",
            "Epoch: 640, loss: 8.038494706852362e-05\n",
            "Epoch: 650, loss: 7.977702625794336e-05\n",
            "Epoch: 660, loss: 7.918366463854909e-05\n",
            "Epoch: 670, loss: 7.860479672672227e-05\n",
            "Epoch: 680, loss: 7.803876360412687e-05\n",
            "Epoch: 690, loss: 7.748355710646138e-05\n",
            "Epoch: 700, loss: 7.693804218433797e-05\n",
            "Epoch: 710, loss: 7.640210242243484e-05\n",
            "Epoch: 720, loss: 7.587597065139562e-05\n",
            "Epoch: 730, loss: 7.535880286013708e-05\n",
            "Epoch: 740, loss: 7.485116657335311e-05\n",
            "Epoch: 750, loss: 7.435293809976429e-05\n",
            "Epoch: 760, loss: 7.386362267425284e-05\n",
            "Epoch: 770, loss: 7.338311115745455e-05\n",
            "Epoch: 780, loss: 7.291058136615902e-05\n",
            "Epoch: 790, loss: 7.244685548357666e-05\n",
            "Epoch: 800, loss: 7.199214451247826e-05\n",
            "Epoch: 810, loss: 7.154686318244785e-05\n",
            "Epoch: 820, loss: 7.111109880497679e-05\n",
            "Epoch: 830, loss: 7.068412378430367e-05\n",
            "Epoch: 840, loss: 7.026811363175511e-05\n",
            "Epoch: 850, loss: 6.986251537455246e-05\n",
            "Epoch: 860, loss: 6.946793291717768e-05\n",
            "Epoch: 870, loss: 6.908442446729168e-05\n",
            "Epoch: 880, loss: 6.871121149742976e-05\n",
            "Epoch: 890, loss: 6.834641681052744e-05\n",
            "Epoch: 900, loss: 6.798922549933195e-05\n",
            "Epoch: 910, loss: 6.763912824681029e-05\n",
            "Epoch: 920, loss: 6.729680171702057e-05\n",
            "Epoch: 930, loss: 6.696335913147777e-05\n",
            "Epoch: 940, loss: 6.663610110990703e-05\n",
            "Epoch: 950, loss: 6.631654832744971e-05\n",
            "Epoch: 960, loss: 6.600246706511825e-05\n",
            "Epoch: 970, loss: 6.568995740963146e-05\n",
            "Epoch: 980, loss: 6.538076559081674e-05\n",
            "Epoch: 990, loss: 6.50778238195926e-05\n",
            "Epoch: 1000, loss: 6.478043360402808e-05\n",
            "Epoch: 1010, loss: 6.448879139497876e-05\n",
            "Epoch: 1020, loss: 6.420285353669897e-05\n",
            "Epoch: 1030, loss: 6.392219802364707e-05\n",
            "Epoch: 1040, loss: 6.364752334775403e-05\n",
            "Epoch: 1050, loss: 6.337800732580945e-05\n",
            "Epoch: 1060, loss: 6.311294418992475e-05\n",
            "Epoch: 1070, loss: 6.285151175688952e-05\n",
            "Epoch: 1080, loss: 6.259360816329718e-05\n",
            "Epoch: 1090, loss: 6.233940075617284e-05\n",
            "Epoch: 1100, loss: 6.208733248058707e-05\n",
            "Epoch: 1110, loss: 6.183851655805483e-05\n",
            "Epoch: 1120, loss: 6.159240729175508e-05\n",
            "Epoch: 1130, loss: 6.135040894150734e-05\n",
            "Epoch: 1140, loss: 6.111222319304943e-05\n",
            "Epoch: 1150, loss: 6.087810470489785e-05\n",
            "Epoch: 1160, loss: 6.064651097403839e-05\n",
            "Epoch: 1170, loss: 6.0417154600145295e-05\n",
            "Epoch: 1180, loss: 6.0192069213371724e-05\n",
            "Epoch: 1190, loss: 5.997153857606463e-05\n",
            "Epoch: 1200, loss: 5.975536987534724e-05\n",
            "Epoch: 1210, loss: 5.954357038717717e-05\n",
            "Epoch: 1220, loss: 5.933615466346964e-05\n",
            "Epoch: 1230, loss: 5.913297718507238e-05\n",
            "Epoch: 1240, loss: 5.8933776017511263e-05\n",
            "Epoch: 1250, loss: 5.873838017578237e-05\n",
            "Epoch: 1260, loss: 5.854708069819026e-05\n",
            "Epoch: 1270, loss: 5.8359935792395845e-05\n",
            "Epoch: 1280, loss: 5.8176265156362206e-05\n",
            "Epoch: 1290, loss: 5.7995937822852284e-05\n",
            "Epoch: 1300, loss: 5.78188628423959e-05\n",
            "Epoch: 1310, loss: 5.764521847595461e-05\n",
            "Epoch: 1320, loss: 5.7474637287668884e-05\n",
            "Epoch: 1330, loss: 5.7306777307530865e-05\n",
            "Epoch: 1340, loss: 5.7141543948091567e-05\n",
            "Epoch: 1350, loss: 5.6978929933393374e-05\n",
            "Epoch: 1360, loss: 5.6819128076313064e-05\n",
            "Epoch: 1370, loss: 5.6661774578969926e-05\n",
            "Epoch: 1380, loss: 5.650692037306726e-05\n",
            "Epoch: 1390, loss: 5.635459456243552e-05\n",
            "Epoch: 1400, loss: 5.620459342026152e-05\n",
            "Epoch: 1410, loss: 5.605686237686314e-05\n",
            "Epoch: 1420, loss: 5.591097578871995e-05\n",
            "Epoch: 1430, loss: 5.5766569857951254e-05\n",
            "Epoch: 1440, loss: 5.56244449398946e-05\n",
            "Epoch: 1450, loss: 5.5484189942944795e-05\n",
            "Epoch: 1460, loss: 5.534581941901706e-05\n",
            "Epoch: 1470, loss: 5.5209206038853154e-05\n",
            "Epoch: 1480, loss: 5.507412788574584e-05\n",
            "Epoch: 1490, loss: 5.494035576703027e-05\n",
            "Epoch: 1500, loss: 5.4807976994197816e-05\n",
            "Epoch: 1510, loss: 5.467725350172259e-05\n",
            "Epoch: 1520, loss: 5.4548003390664235e-05\n",
            "Epoch: 1530, loss: 5.4420386732090265e-05\n",
            "Epoch: 1540, loss: 5.429469092632644e-05\n",
            "Epoch: 1550, loss: 5.417063584900461e-05\n",
            "Epoch: 1560, loss: 5.404803960118443e-05\n",
            "Epoch: 1570, loss: 5.392717139329761e-05\n",
            "Epoch: 1580, loss: 5.380772563512437e-05\n",
            "Epoch: 1590, loss: 5.368950223783031e-05\n",
            "Epoch: 1600, loss: 5.3572664910461754e-05\n",
            "Epoch: 1610, loss: 5.345714816940017e-05\n",
            "Epoch: 1620, loss: 5.334294473868795e-05\n",
            "Epoch: 1630, loss: 5.323002551449463e-05\n",
            "Epoch: 1640, loss: 5.31183322891593e-05\n",
            "Epoch: 1650, loss: 5.300781413097866e-05\n",
            "Epoch: 1660, loss: 5.289834371069446e-05\n",
            "Epoch: 1670, loss: 5.278979006106965e-05\n",
            "Epoch: 1680, loss: 5.268219319987111e-05\n",
            "Epoch: 1690, loss: 5.2575684094335884e-05\n",
            "Epoch: 1700, loss: 5.2470317314146087e-05\n",
            "Epoch: 1710, loss: 5.2366238378454e-05\n",
            "Epoch: 1720, loss: 5.226341090747155e-05\n",
            "Epoch: 1730, loss: 5.216170029598288e-05\n",
            "Epoch: 1740, loss: 5.2060804591747e-05\n",
            "Epoch: 1750, loss: 5.196083293412812e-05\n",
            "Epoch: 1760, loss: 5.18619162903633e-05\n",
            "Epoch: 1770, loss: 5.176398190087639e-05\n",
            "Epoch: 1780, loss: 5.166678602108732e-05\n",
            "Epoch: 1790, loss: 5.157043051440269e-05\n",
            "Epoch: 1800, loss: 5.147483534528874e-05\n",
            "Epoch: 1810, loss: 5.138012784300372e-05\n",
            "Epoch: 1820, loss: 5.1286242523929104e-05\n",
            "Epoch: 1830, loss: 5.119312118040398e-05\n",
            "Epoch: 1840, loss: 5.110077836434357e-05\n",
            "Epoch: 1850, loss: 5.100906128063798e-05\n",
            "Epoch: 1860, loss: 5.091821003588848e-05\n",
            "Epoch: 1870, loss: 5.082815914647654e-05\n",
            "Epoch: 1880, loss: 5.073883221484721e-05\n",
            "Epoch: 1890, loss: 5.065024015493691e-05\n",
            "Epoch: 1900, loss: 5.0562368414830416e-05\n",
            "Epoch: 1910, loss: 5.047514059697278e-05\n",
            "Epoch: 1920, loss: 5.038865492679179e-05\n",
            "Epoch: 1930, loss: 5.0302794988965616e-05\n",
            "Epoch: 1940, loss: 5.0217560783494264e-05\n",
            "Epoch: 1950, loss: 5.013299232814461e-05\n",
            "Epoch: 1960, loss: 5.004902050131932e-05\n",
            "Epoch: 1970, loss: 4.99657508044038e-05\n",
            "Epoch: 1980, loss: 4.988304863218218e-05\n",
            "Epoch: 1990, loss: 4.980095036444254e-05\n",
            "Epoch: 2000, loss: 4.971954695065506e-05\n",
            "Epoch: 2010, loss: 4.963871469954029e-05\n",
            "Epoch: 2020, loss: 4.955851181875914e-05\n",
            "Epoch: 2030, loss: 4.947888010065071e-05\n",
            "Epoch: 2040, loss: 4.939996506436728e-05\n",
            "Epoch: 2050, loss: 4.932153024128638e-05\n",
            "Epoch: 2060, loss: 4.924373934045434e-05\n",
            "Epoch: 2070, loss: 4.9166563258040696e-05\n",
            "Epoch: 2080, loss: 4.9090045649791136e-05\n",
            "Epoch: 2090, loss: 4.901407373836264e-05\n",
            "Epoch: 2100, loss: 4.893861114396714e-05\n",
            "Epoch: 2110, loss: 4.88636942463927e-05\n",
            "Epoch: 2120, loss: 4.8789406719151884e-05\n",
            "Epoch: 2130, loss: 4.871559940511361e-05\n",
            "Epoch: 2140, loss: 4.8642326873959973e-05\n",
            "Epoch: 2150, loss: 4.856961822952144e-05\n",
            "Epoch: 2160, loss: 4.8497444367967546e-05\n",
            "Epoch: 2170, loss: 4.8425757995573804e-05\n",
            "Epoch: 2180, loss: 4.8354566388297826e-05\n",
            "Epoch: 2190, loss: 4.828383316635154e-05\n",
            "Epoch: 2200, loss: 4.821357288165018e-05\n",
            "Epoch: 2210, loss: 4.8143814638024196e-05\n",
            "Epoch: 2220, loss: 4.807463483302854e-05\n",
            "Epoch: 2230, loss: 4.800594979315065e-05\n",
            "Epoch: 2240, loss: 4.7937704948708415e-05\n",
            "Epoch: 2250, loss: 4.786997305927798e-05\n",
            "Epoch: 2260, loss: 4.7802608605707064e-05\n",
            "Epoch: 2270, loss: 4.773572800331749e-05\n",
            "Epoch: 2280, loss: 4.766932761413045e-05\n",
            "Epoch: 2290, loss: 4.760328374686651e-05\n",
            "Epoch: 2300, loss: 4.753770917886868e-05\n",
            "Epoch: 2310, loss: 4.747255297843367e-05\n",
            "Epoch: 2320, loss: 4.740783333545551e-05\n",
            "Epoch: 2330, loss: 4.734347385237925e-05\n",
            "Epoch: 2340, loss: 4.727941632154398e-05\n",
            "Epoch: 2350, loss: 4.7215846279868856e-05\n",
            "Epoch: 2360, loss: 4.715267277788371e-05\n",
            "Epoch: 2370, loss: 4.7089855797821656e-05\n",
            "Epoch: 2380, loss: 4.702745354734361e-05\n",
            "Epoch: 2390, loss: 4.696537143900059e-05\n",
            "Epoch: 2400, loss: 4.690379500971176e-05\n",
            "Epoch: 2410, loss: 4.684267332777381e-05\n",
            "Epoch: 2420, loss: 4.678189361584373e-05\n",
            "Epoch: 2430, loss: 4.672152499551885e-05\n",
            "Epoch: 2440, loss: 4.666162931243889e-05\n",
            "Epoch: 2450, loss: 4.660215199692175e-05\n",
            "Epoch: 2460, loss: 4.654302028939128e-05\n",
            "Epoch: 2470, loss: 4.6484219637932256e-05\n",
            "Epoch: 2480, loss: 4.6425742766587064e-05\n",
            "Epoch: 2490, loss: 4.636775338440202e-05\n",
            "Epoch: 2500, loss: 4.631011688616127e-05\n",
            "Epoch: 2510, loss: 4.6252942411229014e-05\n",
            "Epoch: 2520, loss: 4.619629180524498e-05\n",
            "Epoch: 2530, loss: 4.6140085032675415e-05\n",
            "Epoch: 2540, loss: 4.608430026564747e-05\n",
            "Epoch: 2550, loss: 4.6028919314267114e-05\n",
            "Epoch: 2560, loss: 4.597394581651315e-05\n",
            "Epoch: 2570, loss: 4.591939796227962e-05\n",
            "Epoch: 2580, loss: 4.586524300975725e-05\n",
            "Epoch: 2590, loss: 4.5811510062776506e-05\n",
            "Epoch: 2600, loss: 4.575811544782482e-05\n",
            "Epoch: 2610, loss: 4.570511737256311e-05\n",
            "Epoch: 2620, loss: 4.565242488752119e-05\n",
            "Epoch: 2630, loss: 4.560008892440237e-05\n",
            "Epoch: 2640, loss: 4.554816769086756e-05\n",
            "Epoch: 2650, loss: 4.549658842734061e-05\n",
            "Epoch: 2660, loss: 4.54454384453129e-05\n",
            "Epoch: 2670, loss: 4.539468136499636e-05\n",
            "Epoch: 2680, loss: 4.534428080660291e-05\n",
            "Epoch: 2690, loss: 4.529421858023852e-05\n",
            "Epoch: 2700, loss: 4.524448740994558e-05\n",
            "Epoch: 2710, loss: 4.519512367551215e-05\n",
            "Epoch: 2720, loss: 4.514611282502301e-05\n",
            "Epoch: 2730, loss: 4.5097360271029174e-05\n",
            "Epoch: 2740, loss: 4.504891694523394e-05\n",
            "Epoch: 2750, loss: 4.500078284763731e-05\n",
            "Epoch: 2760, loss: 4.4952928874408826e-05\n",
            "Epoch: 2770, loss: 4.4905369577463716e-05\n",
            "Epoch: 2780, loss: 4.485809040488675e-05\n",
            "Epoch: 2790, loss: 4.4811076804762706e-05\n",
            "Epoch: 2800, loss: 4.476434696698561e-05\n",
            "Epoch: 2810, loss: 4.471787906368263e-05\n",
            "Epoch: 2820, loss: 4.467168400879018e-05\n",
            "Epoch: 2830, loss: 4.4625783630181104e-05\n",
            "Epoch: 2840, loss: 4.458021794562228e-05\n",
            "Epoch: 2850, loss: 4.4534852349897847e-05\n",
            "Epoch: 2860, loss: 4.448976687854156e-05\n",
            "Epoch: 2870, loss: 4.4445001549320295e-05\n",
            "Epoch: 2880, loss: 4.440048724063672e-05\n",
            "Epoch: 2890, loss: 4.43562566943001e-05\n",
            "Epoch: 2900, loss: 4.4312295358395204e-05\n",
            "Epoch: 2910, loss: 4.426860323292203e-05\n",
            "Epoch: 2920, loss: 4.422515849000774e-05\n",
            "Epoch: 2930, loss: 4.4181975681567565e-05\n",
            "Epoch: 2940, loss: 4.413901478983462e-05\n",
            "Epoch: 2950, loss: 4.409636676427908e-05\n",
            "Epoch: 2960, loss: 4.4054031604900956e-05\n",
            "Epoch: 2970, loss: 4.4011954742018133e-05\n",
            "Epoch: 2980, loss: 4.397015436552465e-05\n",
            "Epoch: 2990, loss: 4.3928619561484084e-05\n",
            "Epoch: 3000, loss: 4.388736851979047e-05\n",
            "Epoch: 3010, loss: 4.384637941257097e-05\n",
            "Epoch: 3020, loss: 4.380568498163484e-05\n",
            "Epoch: 3030, loss: 4.3765227019321173e-05\n",
            "Epoch: 3040, loss: 4.372499097371474e-05\n",
            "Epoch: 3050, loss: 4.368502050056122e-05\n",
            "Epoch: 3060, loss: 4.36452537542209e-05\n",
            "Epoch: 3070, loss: 4.360578896012157e-05\n",
            "Epoch: 3080, loss: 4.356654972070828e-05\n",
            "Epoch: 3090, loss: 4.352757605374791e-05\n",
            "Epoch: 3100, loss: 4.3488838855409995e-05\n",
            "Epoch: 3110, loss: 4.345032721175812e-05\n",
            "Epoch: 3120, loss: 4.34120483987499e-05\n",
            "Epoch: 3130, loss: 4.337394784670323e-05\n",
            "Epoch: 3140, loss: 4.333610922913067e-05\n",
            "Epoch: 3150, loss: 4.329854709794745e-05\n",
            "Epoch: 3160, loss: 4.326123234932311e-05\n",
            "Epoch: 3170, loss: 4.322415406932123e-05\n",
            "Epoch: 3180, loss: 4.318726860219613e-05\n",
            "Epoch: 3190, loss: 4.31505250162445e-05\n",
            "Epoch: 3200, loss: 4.3113992433063686e-05\n",
            "Epoch: 3210, loss: 4.307767449063249e-05\n",
            "Epoch: 3220, loss: 4.304153844714165e-05\n",
            "Epoch: 3230, loss: 4.300557338865474e-05\n",
            "Epoch: 3240, loss: 4.296979386708699e-05\n",
            "Epoch: 3250, loss: 4.2934199882438406e-05\n",
            "Epoch: 3260, loss: 4.28987987106666e-05\n",
            "Epoch: 3270, loss: 4.2863626731559634e-05\n",
            "Epoch: 3280, loss: 4.2828651203308254e-05\n",
            "Epoch: 3290, loss: 4.2793861211976036e-05\n",
            "Epoch: 3300, loss: 4.275922765373252e-05\n",
            "Epoch: 3310, loss: 4.2724786908365786e-05\n",
            "Epoch: 3320, loss: 4.269049532013014e-05\n",
            "Epoch: 3330, loss: 4.265636744094081e-05\n",
            "Epoch: 3340, loss: 4.2622428736649454e-05\n",
            "Epoch: 3350, loss: 4.258867193129845e-05\n",
            "Epoch: 3360, loss: 4.255512249073945e-05\n",
            "Epoch: 3370, loss: 4.2521754949120805e-05\n",
            "Epoch: 3380, loss: 4.248853292665444e-05\n",
            "Epoch: 3390, loss: 4.245546369929798e-05\n",
            "Epoch: 3400, loss: 4.24224890593905e-05\n",
            "Epoch: 3410, loss: 4.2389619920868427e-05\n",
            "Epoch: 3420, loss: 4.235691812937148e-05\n",
            "Epoch: 3430, loss: 4.23244055127725e-05\n",
            "Epoch: 3440, loss: 4.229206751915626e-05\n",
            "Epoch: 3450, loss: 4.2259889596607536e-05\n",
            "Epoch: 3460, loss: 4.222783900331706e-05\n",
            "Epoch: 3470, loss: 4.219588663545437e-05\n",
            "Epoch: 3480, loss: 4.216407614876516e-05\n",
            "Epoch: 3490, loss: 4.213240754324943e-05\n",
            "Epoch: 3500, loss: 4.210088445688598e-05\n",
            "Epoch: 3510, loss: 4.2069517803611234e-05\n",
            "Epoch: 3520, loss: 4.203828939353116e-05\n",
            "Epoch: 3530, loss: 4.200719195068814e-05\n",
            "Epoch: 3540, loss: 4.1976210923166946e-05\n",
            "Epoch: 3550, loss: 4.194537177681923e-05\n",
            "Epoch: 3560, loss: 4.1914678149623796e-05\n",
            "Epoch: 3570, loss: 4.188411548966542e-05\n",
            "Epoch: 3580, loss: 4.185372017673217e-05\n",
            "Epoch: 3590, loss: 4.182349948678166e-05\n",
            "Epoch: 3600, loss: 4.179340248811059e-05\n",
            "Epoch: 3610, loss: 4.176341462880373e-05\n",
            "Epoch: 3620, loss: 4.173353954683989e-05\n",
            "Epoch: 3630, loss: 4.170376996626146e-05\n",
            "Epoch: 3640, loss: 4.167413499089889e-05\n",
            "Epoch: 3650, loss: 4.164462734479457e-05\n",
            "Epoch: 3660, loss: 4.16152470279485e-05\n",
            "Epoch: 3670, loss: 4.158600131631829e-05\n",
            "Epoch: 3680, loss: 4.155687929596752e-05\n",
            "Epoch: 3690, loss: 4.152787369093858e-05\n",
            "Epoch: 3700, loss: 4.149897358729504e-05\n",
            "Epoch: 3710, loss: 4.147020445088856e-05\n",
            "Epoch: 3720, loss: 4.1441540815867484e-05\n",
            "Epoch: 3730, loss: 4.141300087212585e-05\n",
            "Epoch: 3740, loss: 4.1384559153812006e-05\n",
            "Epoch: 3750, loss: 4.135623021284118e-05\n",
            "Epoch: 3760, loss: 4.132800313527696e-05\n",
            "Epoch: 3770, loss: 4.129987064516172e-05\n",
            "Epoch: 3780, loss: 4.1271818190580234e-05\n",
            "Epoch: 3790, loss: 4.1243885789299384e-05\n",
            "Epoch: 3800, loss: 4.1216062527382746e-05\n",
            "Epoch: 3810, loss: 4.118836659472436e-05\n",
            "Epoch: 3820, loss: 4.116080526728183e-05\n",
            "Epoch: 3830, loss: 4.113336035516113e-05\n",
            "Epoch: 3840, loss: 4.1106035496341065e-05\n",
            "Epoch: 3850, loss: 4.107878339709714e-05\n",
            "Epoch: 3860, loss: 4.105164043721743e-05\n",
            "Epoch: 3870, loss: 4.102462116861716e-05\n",
            "Epoch: 3880, loss: 4.0997692849487066e-05\n",
            "Epoch: 3890, loss: 4.0970873669721186e-05\n",
            "Epoch: 3900, loss: 4.0944141801446676e-05\n",
            "Epoch: 3910, loss: 4.091751907253638e-05\n",
            "Epoch: 3920, loss: 4.089100184501149e-05\n",
            "Epoch: 3930, loss: 4.0864586480893195e-05\n",
            "Epoch: 3940, loss: 4.0838280256139114e-05\n",
            "Epoch: 3950, loss: 4.081207953277044e-05\n",
            "Epoch: 3960, loss: 4.0785991586744785e-05\n",
            "Epoch: 3970, loss: 4.075999459018931e-05\n",
            "Epoch: 3980, loss: 4.073412492289208e-05\n",
            "Epoch: 3990, loss: 4.07083316531498e-05\n",
            "Epoch: 4000, loss: 4.068266207468696e-05\n",
            "Epoch: 4010, loss: 4.065706889377907e-05\n",
            "Epoch: 4020, loss: 4.063157393829897e-05\n",
            "Epoch: 4030, loss: 4.0606173570267856e-05\n",
            "Epoch: 4040, loss: 4.0580882341600955e-05\n",
            "Epoch: 4050, loss: 4.055569661431946e-05\n",
            "Epoch: 4060, loss: 4.0530594560550526e-05\n",
            "Epoch: 4070, loss: 4.0505598008167e-05\n",
            "Epoch: 4080, loss: 4.048066330142319e-05\n",
            "Epoch: 4090, loss: 4.045582318212837e-05\n",
            "Epoch: 4100, loss: 4.043109220219776e-05\n",
            "Epoch: 4110, loss: 4.040644853375852e-05\n",
            "Epoch: 4120, loss: 4.038190309074707e-05\n",
            "Epoch: 4130, loss: 4.035745223518461e-05\n",
            "Epoch: 4140, loss: 4.033309960504994e-05\n",
            "Epoch: 4150, loss: 4.0308823372470215e-05\n",
            "Epoch: 4160, loss: 4.028463808936067e-05\n",
            "Epoch: 4170, loss: 4.026054739370011e-05\n",
            "Epoch: 4180, loss: 4.023656583740376e-05\n",
            "Epoch: 4190, loss: 4.0212667954619974e-05\n",
            "Epoch: 4200, loss: 4.018886829726398e-05\n",
            "Epoch: 4210, loss: 4.016514867544174e-05\n",
            "Epoch: 4220, loss: 4.014153455500491e-05\n",
            "Epoch: 4230, loss: 4.011800774605945e-05\n",
            "Epoch: 4240, loss: 4.0094557334668934e-05\n",
            "Epoch: 4250, loss: 4.007118695881218e-05\n",
            "Epoch: 4260, loss: 4.004790025646798e-05\n",
            "Epoch: 4270, loss: 4.002471541753039e-05\n",
            "Epoch: 4280, loss: 4.0001614252105355e-05\n",
            "Epoch: 4290, loss: 3.997858220827766e-05\n",
            "Epoch: 4300, loss: 3.99556229240261e-05\n",
            "Epoch: 4310, loss: 3.993277277913876e-05\n",
            "Epoch: 4320, loss: 3.991000630776398e-05\n",
            "Epoch: 4330, loss: 3.9887305320007727e-05\n",
            "Epoch: 4340, loss: 3.986466981587e-05\n",
            "Epoch: 4350, loss: 3.984212162322365e-05\n",
            "Epoch: 4360, loss: 3.9819631638238207e-05\n",
            "Epoch: 4370, loss: 3.9797203498892486e-05\n",
            "Epoch: 4380, loss: 3.977483356720768e-05\n",
            "Epoch: 4390, loss: 3.975250365328975e-05\n",
            "Epoch: 4400, loss: 3.973024649894796e-05\n",
            "Epoch: 4410, loss: 3.970805846620351e-05\n",
            "Epoch: 4420, loss: 3.968595410697162e-05\n",
            "Epoch: 4430, loss: 3.966390431742184e-05\n",
            "Epoch: 4440, loss: 3.964197094319388e-05\n",
            "Epoch: 4450, loss: 3.962009577662684e-05\n",
            "Epoch: 4460, loss: 3.959831519750878e-05\n",
            "Epoch: 4470, loss: 3.957661829190329e-05\n",
            "Epoch: 4480, loss: 3.9555005059810355e-05\n",
            "Epoch: 4490, loss: 3.953347186325118e-05\n",
            "Epoch: 4500, loss: 3.951200415031053e-05\n",
            "Epoch: 4510, loss: 3.9490594645030797e-05\n",
            "Epoch: 4520, loss: 3.9469254261348397e-05\n",
            "Epoch: 4530, loss: 3.944799391319975e-05\n",
            "Epoch: 4540, loss: 3.9426813600584865e-05\n",
            "Epoch: 4550, loss: 3.940572059946135e-05\n",
            "Epoch: 4560, loss: 3.938468944397755e-05\n",
            "Epoch: 4570, loss: 3.936374559998512e-05\n",
            "Epoch: 4580, loss: 3.934284904971719e-05\n",
            "Epoch: 4590, loss: 3.932204344891943e-05\n",
            "Epoch: 4600, loss: 3.930130696971901e-05\n",
            "Epoch: 4610, loss: 3.928063961211592e-05\n",
            "Epoch: 4620, loss: 3.926003773813136e-05\n",
            "Epoch: 4630, loss: 3.923951953765936e-05\n",
            "Epoch: 4640, loss: 3.9219063182827085e-05\n",
            "Epoch: 4650, loss: 3.919868322554976e-05\n",
            "Epoch: 4660, loss: 3.917836511391215e-05\n",
            "Epoch: 4670, loss: 3.915811248589307e-05\n",
            "Epoch: 4680, loss: 3.913793625542894e-05\n",
            "Epoch: 4690, loss: 3.911783642251976e-05\n",
            "Epoch: 4700, loss: 3.909779479727149e-05\n",
            "Epoch: 4710, loss: 3.9077811379684135e-05\n",
            "Epoch: 4720, loss: 3.9057886169757694e-05\n",
            "Epoch: 4730, loss: 3.903802280547097e-05\n",
            "Epoch: 4740, loss: 3.901821037288755e-05\n",
            "Epoch: 4750, loss: 3.899845250998624e-05\n",
            "Epoch: 4760, loss: 3.89787855965551e-05\n",
            "Epoch: 4770, loss: 3.895914414897561e-05\n",
            "Epoch: 4780, loss: 3.8939586374908686e-05\n",
            "Epoch: 4790, loss: 3.8920072256587446e-05\n",
            "Epoch: 4800, loss: 3.890061634592712e-05\n",
            "Epoch: 4810, loss: 3.888122228090651e-05\n",
            "Epoch: 4820, loss: 3.8861882785568014e-05\n",
            "Epoch: 4830, loss: 3.8842594221932814e-05\n",
            "Epoch: 4840, loss: 3.882337114191614e-05\n",
            "Epoch: 4850, loss: 3.8804188079666346e-05\n",
            "Epoch: 4860, loss: 3.87850814149715e-05\n",
            "Epoch: 4870, loss: 3.876602931995876e-05\n",
            "Epoch: 4880, loss: 3.874703907058574e-05\n",
            "Epoch: 4890, loss: 3.872811794281006e-05\n",
            "Epoch: 4900, loss: 3.870923683280125e-05\n",
            "Epoch: 4910, loss: 3.8690432120347396e-05\n",
            "Epoch: 4920, loss: 3.8671656511723995e-05\n",
            "Epoch: 4930, loss: 3.8652957300655544e-05\n",
            "Epoch: 4940, loss: 3.86343126592692e-05\n",
            "Epoch: 4950, loss: 3.861570803564973e-05\n",
            "Epoch: 4960, loss: 3.85971725336276e-05\n",
            "Epoch: 4970, loss: 3.857867341139354e-05\n",
            "Epoch: 4980, loss: 3.856022158288397e-05\n",
            "Epoch: 4990, loss: 3.854183160001412e-05\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nQQSNb07W0D",
        "colab_type": "text"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxVoM1c_7Zrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbT65jHXk0k6",
        "colab_type": "text"
      },
      "source": [
        "## Train loss vs test loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJztT-c5k0Cw",
        "colab_type": "code",
        "outputId": "3efb0a5b-8a0e-453e-8a8e-51fb67fe0b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(train_loss_history[-100:], c=\"y\"), plt.plot(val_loss_history[-100:], c=\"g\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.lines.Line2D at 0x7fa789470160>],\n",
              " [<matplotlib.lines.Line2D at 0x7fa78bece400>])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEWFqIHfk6bR",
        "colab_type": "text"
      },
      "source": [
        "## Final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq3hPqlf1kBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = net(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K96ALc3S2nbQ",
        "colab_type": "code",
        "outputId": "3c4ba8ef-42da-4eb2-b86b-8da0a0c3969d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "count = 50\n",
        "plt.scatter(range(count),test_y.numpy()[:count], alpha=0.7, c='g'), plt.scatter(range(count), y_hat.detach().numpy()[:count], alpha=0.7, c='r')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<matplotlib.collections.PathCollection at 0x7fa78949f400>,\n",
              " <matplotlib.collections.PathCollection at 0x7fa78d4fd1d0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3df3Dc9X3n8efLNjJYso1xZDdgQGpMmjEJ0CJIMiVRfkw4ksvVydQukJRwN0lNJlVLJg4N9C4cMEc7hKGQVrQdWkgp0xwEevTca1JoS6IeSepaJCZgOBqBnGKTWAb8A8nBwvH7/tivYS12pV3pu/vd/X5fjxmNtN/97lffz+53v+/v59f7q4jAzMyKZ17WO2BmZtlwADAzKygHADOzgnIAMDMrKAcAM7OCWpD1DtTjDW94Q/T09GS9G2ZmbeWRRx55PiK6py5vqwDQ09PD8PBw1rthZtZWJP2o0nI3AZmZFZQDgJlZQTkAmJkVlAOAmVlBOQCYmRVUW40CMrP0DG0fYnDLIKN7Ruld1svAOQP09/RnvVvWRK4BmBXQ0PYhNj64kbGJMVZ2rWRsYoyND25kaPtQ1rtmTeQAYFZAg1sG6ezoZMnCJczTPJYsXEJnRyeDWwaz3jVrIgcAswIa3TNKV0fXUcu6OroY3TOa0R5ZFhwAzAqod1kv45PjRy0bnxynd1lvRntkWXAAMCuggXMGmJicYP/B/RyOw+w/uJ+JyQkGzhnIetesiRwAzAqov6efm86/iRWdK9g1vosVnSu46fybPAqoYDwM1Kyg+nv6fcIvONcAzMwKygHAzKygHADMzArKAcDMrKBqCgCSLpD0lKQRSVdWeH6hpHuS5zdL6pny/CmSxiV9vmzZdkmPSdoqybf5MjNrshkDgKT5wK3AB4E1wMWS1kxZ7ZPAnohYDdwM3DDl+T8AvlFh8++NiLMioq/uPTczszmppQZwLjASEc9ExCRwN7B2yjprgTuTv+8D3i9JAJI+AowC29LZZTMzS0MtAeAk4NmyxzuSZRXXiYhDwD5guaQu4AvAtRW2G8CDkh6RtKHaP5e0QdKwpOHdu3fXsLtmZlaLRncCXwPcHBHjFZ47LyJ+iVLT0m9KenelDUTEbRHRFxF93d3dDdxVM7NiqWUm8E7g5LLHq5JlldbZIWkBsBR4AXg7sE7Sl4DjgcOSXo6IwYjYCRARY5Lup9TU9M9zKo2ZmdWslhrAFuA0Sb2SOoCLgE1T1tkEXJr8vQ54KEreFRE9EdED3AL8XkQMSuqUtBhAUidwPvB4CuUxM7MazVgDiIhDkgaAB4D5wB0RsU3SdcBwRGwCbgfukjQCvEgpSExnJXB/0k+8APhqRPz9HMphZmZ1UkRkvQ816+vri+FhTxkwM6uHpEcqDbf3TGAzs4JyADAzKygHADOzgnIAMDMrKAcAM7OCcgAwMysoBwAzs4JyADAzKygHADOzgnIAMDMrKAcAM7OCcgAwMysoBwAzs4JyADAzKygHADOzgnIAMDMrKAcAM7OCcgAwMysoBwAzs4KqKQBIukDSU5JGJF1Z4fmFku5Jnt8sqWfK86dIGpf0+Vq3aWZmjTVjAJA0H7gV+CCwBrhY0popq30S2BMRq4GbgRumPP8HwDfq3KaZmTVQLTWAc4GRiHgmIiaBu4G1U9ZZC9yZ/H0f8H5JApD0EWAU2FbnNs3MrIFqCQAnAc+WPd6RLKu4TkQcAvYByyV1AV8Arp3FNgGQtEHSsKTh3bt317C7ZmZWi0Z3Al8D3BwR47PdQETcFhF9EdHX3d2d3p6ZmRXcghrW2QmcXPZ4VbKs0jo7JC0AlgIvAG8H1kn6EnA8cFjSy8AjNWzTzMwaqJYAsAU4TVIvpZP0RcDHpqyzCbgU+C6wDngoIgJ415EVJF0DjEfEYBIkZtqmmZk10IwBICIOSRoAHgDmA3dExDZJ1wHDEbEJuB24S9II8CKlE3rd25xjWczMrA4qXai3h76+vhgeHs56N8zM2oqkRyKib+pyzwQ2MysoBwAzs4JyADAzKygHADOzgnIAMDMrKAcAM7OCcgAwMysoBwAzs4KqJRWEJYa2DzG4ZZDRPaP0Lutl4JwB+nv6s94ts8Lyd3JuXAOo0dD2ITY+uJGxiTFWdq1kbGKMjQ9uZGj7UNa7ZlZI/k7OnQNAjQa3DNLZ0cmShUuYp3ksWbiEzo5OBrcMZr1rZoXk7+TcOQDUaHTPKF0dXUct6+roYnTPaEZ7ZFZs/k7OnQNAjXqX9TI+efR9bcYnx+ld1pvRHpkVm7+Tc+cAUKOBcwaYmJxg/8H9HI7D7D+4n4nJCQbOGch618wKyd/JuXMAqFF/Tz83nX8TKzpXsGt8Fys6V3DT+Td5xIFZRvydnDvfD8DMLOeq3Q/A8wAy4LHLZtYK3ATUZB67bGatoqYAIOkCSU9JGpF0ZYXnF0q6J3l+s6SeZPm5krYmP49K+mjZa7ZLeix5rjDtOh67bGatYsYmIEnzgVuBDwA7gC2SNkXEE2WrfRLYExGrJV0E3ABcCDwO9CU3gX8j8Kikv42IQ8nr3hsRz6dZoFY3umeUlV0rj1rmsctmloVaagDnAiMR8UxETAJ3A2unrLMWuDP5+z7g/ZIUEQfKTvbHAu3T49wgHrtsZq2ilgBwEvBs2eMdybKK6yQn/H3AcgBJb5e0DXgM+HRZQAjgQUmPSNpQ7Z9L2iBpWNLw7t27aylTS/PYZTNrFQ3vBI6IzRFxOnAOcJWkY5OnzouIXwI+CPympHdXef1tEdEXEX3d3d2N3t2G89hlM2sVtQwD3QmcXPZ4VbKs0jo7JC0AlgIvlK8QEU9KGgfeCgxHxM5k+Zik+yk1Nf3zrErRZvp7+n3CN7PM1VID2AKcJqlXUgdwEbBpyjqbgEuTv9cBD0VEJK9ZACDpVOAtwHZJnZIWJ8s7gfMpdRibmVmTzFgDSEbwDAAPAPOBOyJim6TrKF3JbwJuB+6SNAK8SClIAJwHXCnpFeAw8JmIeF7SzwP3SzqyD1+NiL9Pu3BmZladU0GYmeWcU0FM4XQMZlZ0hUwF4XQMZmYFDQBOx2BmVtAA4FvJmZkVNADkKR3D0PYh1t+7nr7b+lh/73o3Y5lZzQoZAPKSjsF9GWY2F4UMAHlJx+C+DDObi8IOA81DOganljazuShkDSAv8tSXYWbN5wDQxvLSl2Fm2XAAaGN56cuwjAwNwfr10NdX+j3kwQNF41xAZkU0NAQbN0JnJ3R1wfg4TEzATTdBvy8gGmZoCAYHYXQUenthYKAp73e1XECuAVhL8zyHBhkcLJ38lyyBefNKvzs7S8utMY4E3bExWLmy9HvjxkxrXg4AWShq1bvOcnueQwONjpau/Mt1dZWWW2O0YNB1AGi2FrwKaIpZlNvzHBqot7fU7FNufLy03BqjBYOuA0CzteBVQFPMotzO2ZSCarWugYFSm//+/XD4cOn3xERpuTVGCwZdB4Bma8GrgKaYRbk9z2GOpqt19feXOnxXrIBdu0q/3QHcWC0YdIsbALJqh2/Bq4CmmEW5Pc9hjmaqdfX3w733wvBw6bdP/pWlda5owaBbUwCQdIGkpySNSLqywvMLJd2TPL9ZUk+y/FxJW5OfRyV9tNZtNlSW7fAteBXQFLMot+c5zFFRa5tpSvtc0WJBd8Z5AJLmA/8GfADYAWwBLo6IJ8rW+QxwRkR8WtJFwEcj4kJJi4DJ5MbybwQeBU4EYqZtVpLaPID160sf5JIlry3bvx9WrGDoxoG6bxVZ9+0lMxoLnLmiljsr0xzn3HtvdvuVtXqOw5y8h9XmAdQSAN4JXBMR/yF5fBVARPx+2ToPJOt8V9IC4CdAd5RtXFIv8C/AScA5M22zktQCQF9fKZrPK6sAHT7MS/8+wnt/azGdHZ10dXQxPjnOxOTEtFedR4Yq1vMas6bwZK/Xq/c9qXKuYNeu0lV8m5jLRLCTgGfLHu9IllVcJyIOAfuA5ck/frukbcBjwKeT52vZZuNUaY9+rGui7mGHHqpoLasF25wzV+9otJz32TW8EzgiNkfE6ZSu+q+SdGw9r5e0QdKwpOHdu3ens1NV2qO/8suL6h526KGK1tJarM05c/X2i+S8z66WALATOLns8apkWcV1kiagpcAL5StExJPAOPDWGrd55HW3RURfRPR1d3fXsLs1qHJltPftZ9Y97NBDFc3aSL1X9DmvRdVyQ5gtwGlJG/5O4CLgY1PW2QRcCnwXWAc8FBGRvObZpBP4VOAtwHZgbw3bbKz+/td9iAPbYeODGwGOas8feE/1aD9wzkDdrzGzjAwMlPoA4Og+gOmu6CucK1KX0QCJGWsASZv9APAA8CTwtYjYJuk6Sb+SrHY7sFzSCPA54MiwzvOARyVtBe4HPhMRz1fbZpoFm43ZDDv0UEUrjDzksGrFK/oMh6U7HbSZzcwjihqnCUNNnQ46A05lbLlR1BxWzZDhhD0HgAZxKuM65aF5Ic88q7hxMhxq6gDQIJ4fUIeipshuJzkfD5+pDIeaOgBMldKVqOcH1KHIzQvtUvNp1fHw7fL+TSfDjmkHgHIpXol6fkAditq80E41n/5+tl5xCd+ZfJonHv8W35l8mq1XXFLY0TNpGzoV1v8a9G0o/R46tTn/1wGgXIpXok5lXIeiNi+0Uc1naPsQn9p3F1dd9iau+P33cNVlb+JT++7Ktk+rjd6/6WTZX+gAUC7FK1HPD6hDqzYvNFob1Xxask+rjd6/6WT53tYyE7g4entfPx53Dlei/T39uT7h150Gu5ojbaB1zIRM7X9nKeXjrZFG94yysmvlUcua2ae19Z4vc+CWGzn+uT3sPXEZiz57BWe10fs3nSzfW9cAyhX1SnQWUq+21pG0LDdDbNvoeMuyT2vrPV9m4e/8LotefImXTuhk0YsvsfB3fpcfrvm5tnn/ppPle+sAUK4Vp4m3qCyrrS3ZHDEbbXS8ZdmndeCWGzl47AImO49FEpOdx3Lw2AXsfvD+tnn/ppPle+tUEDYrfbf1sbJrJfP02jXE4TjMrvFdDG9o7GeU5f8usqya3Z44tZOXTuhE0qvLIoLFL06w5kcTDf//zdDo97ZaKgj3Adis9C7rZWxijCULX2t/bVa1Ncv/nbZ26svIqk9r74nLWPTiS0x2vnYrkYUHDrL3xGVN35dGyeq9zX8TUB4mirSgLKuteRlim5u+jAZb9NkrWPjyITomXiYi6Jh4mYUvH2LRZ6/IetfaXr4DQNoTRRxMXjXtMNcGv095GWKbm76MBjvrwss5+KXf48AJi1n84gQHTljMwS/9HmddeHnWu9Z4Df4u5bsPIM00q06HWxu/TzVzX4ZNK8XvUjHTQac5UWQ2sw6LWGPIyezMZnC6EJtWE75L+Q4AaaYYqDeY5ChPSV1yMjuzGfLSl2EN0oTvUr4DQJoTbeoNJkW9Ei5qXp9ZyEtfhlWQRu2/Cd+lfAeANCfa1BtMinol3EazW1tBf08/966/l+ENw9y7/l6f/PMgrdp/E75LNQUASRdIekrSiKQrKzy/UNI9yfObJfUkyz8g6RFJjyW/31f2mm8l29ya/KxIq1BHqSPFwIzbqSeYFPVKuI1mtzaLbw1aMGnV/puQgnvGUUCS5gP/BnwA2AFsAS6OiCfK1vkMcEZEfFrSRcBHI+JCSb8I7IqI5yS9FXggIk5KXvMt4PMRUfNwh7aaCezRMMZrY/07Ozrp6uhifHKcickJN/XkWV9f6cp/Xtn19eHDpQuiOs5faR47cxkFdC4wEhHPRMQkcDewdso6a4E7k7/vA94vSRHx/Yh4Llm+DThO0sK69rxd+UrY8Fj/Qkqp9t+MY6eWAHAS8GzZ4x3JsorrRMQhYB+wfMo6vwp8LyIOli37StL880WVJ/ooI2mDpGFJw7t3765hd1tIWs1PzVDEIatpq/Ae+tagBZRS230zjp2mdAJLOh24AbisbPHHI+JtwLuSn0sqvTYibouIvojo6+7ubvzOFlFRh6ymqcp7+KHnOjMd6+/+hzqkdRE0Te2/ns+jGfNEagkAO4GTyx6vSpZVXEfSAmAp8ELyeBVwP/CJiHj6yAsiYmfy+yXgq5SamiwLRR2yOluVThRV3sOBf1VmY/1bOtdQq9U4074IqlD7r/fzaMY8kVoCwBbgNEm9kjqAi4BNU9bZBFya/L0OeCgiQtLxwN8BV0bEt4+sLGmBpDckfx8DfBh4fG5FsVkr6pDV2ah2ovjBDyq+hyvGxtMd61/HibNl+x9ascbZhIugej+PZswTmTEddEQckjQAPADMB+6IiG2SrgOGI2ITcDtwl6QR4EVKQQJgAFgNXC3p6mTZ+cAE8EBy8p8P/CPwZ6mVyurTArfWa5u0yOUnCnjt909+wt7ndzByaDcHXjnAomMWsXpBN8f3vjm9VL/lI8vKT5xVBhdkfRvHqqq9h4OD2fWTjY7ywuJjGH3ukVc/v94lp7J8lhdBlY7n2XwejU4TXVMfQER8PSLeHBFviojrk2VXJyd/IuLliFgfEasj4tyIeCZZ/j8iojMizir7GYuIiYg4OyLOiIjTI+LyiPhZw0ppr6l0BZnx5K2WbqqYqkpt6cAx4sc/GWHB+AQL53ewYHyCH/9khK3rzkvvf9d5lTrrNuR6m2fqXX+6GmdGTUNjK7rYvuNxJn92kIULFjL5s4Ns3/E4Yyu6Zn7xFNWO5yNDOctlnfsp3zOB7WjVqt6Q6ZDVlm2qqKTKEL+tPxf88cWrGV/WyQn7Jhlf1skfX7ya6+c9nN7/rrOpblZtyPU2z8ymOafaMMnOzsyahgbPDbpegcUHQREsPghdr5SW172tKsdzEC2X+8kBoEimu4LMcMhqWw2VrFJb+sovL+KZM1Zxw+Vn87nr38UNl5/NM2esSrcMdY4vn1Ubcr1t4bNpO69W45QyG4zw9RMnuP2S09m3dCHL9k2yb+lCbr/kdL5+Yv23nKx2PB+ZxNVKuZ98S8h2cWSkyeho6Qs/MDD9SbrS+qOjpSurci3Q2TvtLR7rLXejHRniN2Wf9o4NMt7o21QODLxWYyufXT5NU13dbcj1HiOzOaaSFAcHbrmR4x/fU7rl4xVXcNaNd2V2fPYu62VzxxhPrjn71WX7D+6nt/PkaV5VfVvVjuesbv1YjWsA7SCtavmRk0a5FshPVK2p4r8ePq96ubMcRlihttSU1M7NmF1e7yzWWcx6Hdo+xKf23cVVl72JK37/PVx12Zv41L67Su3tGR2faX5+7ZTm2wEgDY0+GaVVLY9oyUyd1Zoqzrrv4crluPrqlhtG2LTUzo1uqqt3QMAsBhBU7fM5N7vjM83Pr53SfOf7lpDN0Iykb/Uml5pu/QrNFy2boqJaOb7zHTjjjHRu9Wmvl0Zz4zTrT3srzF9oo+OzjVRLBuc+gLlqxpjm3l72/vu/VRxjXm39quP6+/vb5wtVrRyQ7sS1VutnyFq9x8g061caDz9dG/nQqTD4azC6B3qXwcCpkPUn0TZzVGbBTUBz1YRZtFvXnVffGPO83JSlWjnOPDO9tuJWnJWaE9XGw5938nkV28jPO/m8lpsP0lZzVGbBAWCumnDjl+vnPVzfGPO8pKKuVo5rr00vwDkPUsMMbhnknc+8wvV/+kNu+W/f5vo//SHvfOYVHn724Ypt5A8/+3DLzQdpqzkqs+AmoLmaxdC8eo3uGeXAGau44cxTXl12OA6za7ox5mk29WTZRFKtHGn1ZbTo0Ng8OH7zo/z2X+/i5WMXsGdpB0v3HeS379nOlw79lP71rx8OufHBjS2XumLa9A05aDp0DWCumnC13Yy0sFWl2ESSamriaqNh6h2R1Wa37myn9M7/5dsHmOiAnx63ACR+etwCJjpKyytJ/TivciykkZL5Q89lN2s5TQ4AaWjw0LxMxxWn1ETSlLbU2QSrNuovabf26LeNd7K/Aw4dPkRQ+r2/o7S8klSP8yrHwtZ7vpxOSuZ/zW7WcpocANpApuOKU+rkbkpb6myCVRv1l7Rbe/Tit5zBGYt66Ji/kIOHDtIxfyFnLOph8VvOqLh+qsd5lWPhwC03ppKSecXYeC5SqLsPoE1kNoU8pVTRTUlNPNv2/DYZGtt27dEDAxy/cSN9Xac1LnVFNVWOheMf31N33qmK+9QCKdTT4BqATS+lJpKm9GNM054/q7bzFNqQZ63C/2679ugsa1dVjoW9Jy5L5zhso6bD6XgmsM0shavLI+3XnR2dr+ZFP5IdMbWaTZVZ2VuvuIRbt9zKx4b2sOr5SXa8oYOv9i/j1wf+rPr/nmZbn9p3V2blqPS/v/43XayYCM+MLteMz68Va11VVJsJ7ABgTdOUGZUVvpRXf/NqPv4X32PyuA5+eux8jnv5Z3T8dJK/+s+/xHXXVLlKXr/+9VX8/fv5zuTTXHXZm46axbr/4H5WdK7g3vUpnWyr/G9WrGDoxoHXv4frNtaXKqQoqpyg8zyztxqngmgHbXRFMRtN6ceo0J7/7s/9gIPHdfDycaXD/afHLSCAd//tD+CaKttJsQ25btP0ZTSjPTovJ8hqaSVaLSVzlmrqA5B0gaSnJI1IurLC8wsl3ZM8v1lST7L8A5IekfRY8vt9Za85O1k+IukPJSmtQrUlpyRomN69MN5xdE13vCPo3TvdixrchjydeucmpNge3W5DTavJSzkabcYAIGk+cCvwQWANcLGkNVNW+ySwJyJWAzcDNyTLnwf+U0S8DbgUuKvsNX8C/AZwWvJzwRzK0f6ckqBhFv/CmSw88MpR49EXHniFxb9wZvUXVTmpLvrsFY2fk1HvCT3FztZ2G2paTV7K0Wi11ADOBUYi4pmImATuBtZOWWctcGfy933A+yUpIr4fEc8ly7cBxyW1hTcCSyLiX6LUCfGXwEfmXJp21oSkcqnL8qYsdVjxhWt587EnsvTgPA6+8jJLD87jzceeyIovXFv9RVVOqmddeHnj52TM5oSe0mTEtro95zTyUo5Gq6UP4CTg2bLHO4C3V1snIg5J2gcsp1QDOOJXge9FxEFJJyXbKd/mSZX+uaQNwAaAU045pdIq+VBvyucZNLwdt3yURXmTVStOourvZ/HgbZx+pH/lLUf3r1R9r6rMD8iqL6MZpr09ZxvJSzkarSnzACSdTqlZ6LJ6XxsRt0VEX0T0dXd3p79zLaLulM/TaEr7Z7s1WVW5QnZb8dHa6XaG08lLORqtlgCwEyi/M/KqZFnFdSQtAJYCLySPVwH3A5+IiKfL1l81wzYLpe6Uz9NoSvtnOzZZVdCU96pNmsqgvW5nOJ28lKPRamkC2gKcJqmX0kn6IuBjU9bZRKmT97vAOuChiAhJxwN/B1wZEd8+snJE/FjSfknvADYDnwD+aM6laWOzSvkMFYeONiXtQk6mwjf8vWqnprJEXoZJ5qUcjTRjDSAiDgEDwAPAk8DXImKbpOsk/Uqy2u3AckkjwOeAI0NFB4DVwNWStiY/K5LnPgP8OTACPA18I61CtaNZpUqoMnT0Q891Nn6o4jQjVdopZXHDU1Q0qaksy/e8nT5vO5pnAreIWaVKqDJjdKxTfOgj441NVwAVax9Dp9L4lA8paniKimo3tk9xlm5T0my04P+22lWbCexkcC1iVm2WVdrhV4yNN6f9s0LHaruNv254W3ETbjiT5Xvebp+3Hc2pIFpI3W2W07TDZ9X+2ZT+h5Q19L1q0i1Ds3rP2/Hztte4BtDOWjAlbaa3r0xZKm3bOb9laJ4+7yJyAGhnLXg3q7yMv051fkCObxmal8+7qNwJbKnLQzbJ9feuf91M0tTTPqcoy/c8D5933vl+AGZ16Lutj5VdK5mn1yrJh+Mwu8Z3MbzBx6C1F48CMquD27atCBwAzCpw27YVgQOAWQXOJWNF4HkAZlU4l4zlnQOA5YpHpJjVzk1AlhvO7W9WHwcAyw3npTGrjwOA5YbvA2vNlIc02A4Alhseu2/NkpfmRgcAyw2P3bdmyUtzowOA5YbH7luz5KW5MffDQD0ssFjyMnbfx21r613W+7pkge3Y3FhTDUDSBZKekjQi6coKzy+UdE/y/GZJPcny5ZK+KWlc0uCU13wr2ebUewWnJi/tdFYsPm5bX16aG2cMAJLmA7cCHwTWABdLWjNltU8CeyJiNXAzcEOy/GXgi8Dnq2z+4xFxVvIzNpsCTCcv7XRWLD5uW19emhtraQI6FxiJiGcAJN0NrAWeKFtnLXBN8vd9wKAkRcQE8LCk1entcu18uzprRz5u20MemhtraQI6CXi27PGOZFnFdSLiELAPWF7Dtr+SNP98UZJqWL8uHhb4enkYu5x3Pm6tWbIcBfTxiHgb8K7k55JKK0naIGlY0vDu3bvr+gd5aadLi9uW24OPW2uWWgLATuDksserkmUV15G0AFgKvDDdRiNiZ/L7JeCrlJqaKq13W0T0RURfd3d3Dbv7mry006XFbcvtwcetNUstfQBbgNMk9VI60V8EfGzKOpuAS4HvAuuAh2Kae00mQeL4iHhe0jHAh4F/nMX+zygP7XRpcdty+/Bxa80wYwCIiEOSBoAHgPnAHRGxTdJ1wHBEbAJuB+6SNAK8SClIACBpO7AE6JD0EeB84EfAA8nJfz6lk/+fpVoye528jF02s3TUNBEsIr4OfH3KsqvL/n4ZWF/ltT1VNnt2bbtoaRk4Z4CND24ESlf+45Pjpbbl97ht2ayInAqiQNy2bGblcp8Kwo7mtmUzO8I1ADOzgnIAMDMrKAcAM7OCch+AAU4/bFZErgGYU0SYFZQDgDlFhFlBOQBYbm5vZ2b1cQAwpx82KygHAHP6YbOCcgAwp4gwKygPAzXAKSLMisgBwGbkOQJm+eQmIJuW5wiY5ZcDgE3LcwTM8ssBwKblOQJm+eUAYNPyHAGz/HIAsGl5joBZftUUACRdIOkpSSOSrqzw/EJJ9yTPb5bUkyxfLumbksYlDU55zdmSHkte84eSlEaBLF2eI2CWXzMOA5U0H7gV+ACwA9giaVNEPFG22ieBPRGxWtJFwA3AhcDLwBeBtyY/5f4E+A1gM6Ubzl8AfGNuxbFG8BwBs3yqpQZwLjASEc9ExCRwN7B2yjprgTuTv+8D3i9JETEREQ9TCgSvkvRGYElE/EtEBPCXwCbtED0AAAQqSURBVEfmUhAzM6tPLQHgJODZssc7kmUV14mIQ8A+YPkM29wxwzYBkLRB0rCk4d27d9ewu2ZmVouW7wSOiNsioi8i+rq7u7PeHTOz3KglAOwETi57vCpZVnEdSQuApcALM2xz1QzbNDOzBqolAGwBTpPUK6kDuAjYNGWdTcClyd/rgIeStv2KIuLHwH5J70hG/3wC+N91772Zmc2apjlPv7aS9CHgFmA+cEdEXC/pOmA4IjZJOha4C/hF4EXgooh4JnntdmAJ0AHsBc6PiCck9QF/ARxHafTPb00XNJJt7QZ+NJuCAm8Anp/la9uZy10sLnex1FruUyPidW3oNQWAPJA0HBF9We9Hs7ncxeJyF8tcy93yncBmZtYYDgBmZgVVpABwW9Y7kBGXu1hc7mKZU7kL0wdgZmZHK1INwMzMyjgAmJkVVO4DwEyprPNE0h2SxiQ9XrbsBEn/IOmHye9lWe5jI0g6OUk7/oSkbZIuT5bnuuySjpX0r5IeTcp9bbK8N0nLPpKkae/Iel8bQdJ8Sd+X9H+Sx7kvt6TtSRr9rZKGk2WzPs5zHQDKUll/EFgDXCxpTbZ71VB/QSmtdrkrgX+KiNOAf0oe580hYGNErAHeAfxm8jnnvewHgfdFxJnAWcAFkt5BKR37zRGxGthDKV17Hl0OPFn2uCjlfm9EnFU2/n/Wx3muAwC1pbLOjYj4Z0ozscuVp+q+kxym3Y6IH0fE95K/X6J0UjiJnJc9So7cr/OY5CeA91FKyw45LDeApFXAfwT+PHksClDuKmZ9nOc9ANSSyjrvVia5lwB+AqzMcmcaLbkb3S9SutFQ7sueNINsBcaAfwCeBvYmadkhv8f8LcDvAIeTx8spRrkDeFDSI5I2JMtmfZzPeEcwy4+ICEm5HfcrqQv4a+CzEbG//C6jeS17RPwMOEvS8cD9wFsy3qWGk/RhYCwiHpH0nqz3p8nOi4idklYA/yDp/5U/We9xnvcaQC2prPNuV3IHtiN3YhvLeH8aQtIxlE7+fxUR/ytZXIiyA0TEXuCbwDuB45O07JDPY/6XgV9JEk3eTanp58vkv9xExM7k9xilgH8uczjO8x4AakllnXflqbovJYdpt5P239uBJyPiD8qeynXZJXUnV/5IOo7SfbufpBQI1iWr5a7cEXFVRKyKiB5K3+mHIuLj5LzckjolLT7yN3A+8DhzOM5zPxO4UirrjHepYST9T+A9lFLE7gL+O/A3wNeAUyil0v61iJjaUdzWJJ0H/F/gMV5rE/5dSv0AuS27pDModfrNp3Qx97WIuE7Sz1O6Mj4B+D7w6xFxMLs9bZykCejzEfHhvJc7Kd/9ycMFwFeT1PzLmeVxnvsAYGZmleW9CcjMzKpwADAzKygHADOzgnIAMDMrKAcAM7OCcgAwMysoBwAzs4L6/78Y7ViDGus9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UKDZI5O4YF2",
        "colab_type": "code",
        "outputId": "0ad9143a-66ad-44d4-f406-b96182acac22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(test_x.detach().numpy()[:5] * 1640)\n",
        "print(test_y.detach().numpy()[:5] * 1640)\n",
        "print(y_hat.detach().numpy()[:5] * 1640)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 492.00003   243.72223   615.        615.        649.1667   1640.\n",
            "  1640.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.       1640.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.      ]\n",
            " [   4.555556  482.8889    922.5       922.5       956.6666      0.\n",
            "     0.          0.       1640.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "  1640.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.      ]\n",
            " [ 212.97223    74.02778  1537.5      1537.5      1571.6666      0.\n",
            "     0.          0.       1640.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.       1640.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.      ]\n",
            " [ 351.9167    305.22223  1195.8334   1195.8334   1264.1666      0.\n",
            "  1640.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.       1640.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.      ]\n",
            " [ 383.80554   370.1389   1264.1666   1264.1666   1332.5      1640.\n",
            "  1640.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "  1640.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.\n",
            "     0.          0.          0.      ]]\n",
            "[[25.055555]\n",
            " [54.666668]\n",
            " [48.97222 ]\n",
            " [60.36111 ]\n",
            " [48.97222 ]]\n",
            "[[43.126106]\n",
            " [49.691082]\n",
            " [45.652096]\n",
            " [42.79177 ]\n",
            " [37.030315]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwwK4rZbjSw7",
        "colab_type": "text"
      },
      "source": [
        "print for test methods:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHMQ-KxtdKj6",
        "colab_type": "code",
        "outputId": "fc686bf1-bd0d-4fa8-b8b0-4f27987443ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(test_x.detach().numpy()[:10] * 1440)\n",
        "print(test_y.detach().numpy()[:10] * 1440)\n",
        "print(y_hat.detach().numpy()[:10] * 1440)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.3200003e+02 2.1400000e+02 5.4000000e+02 5.4000000e+02 5.7000000e+02\n",
            "  1.4400000e+03 1.4400000e+03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  1.4400000e+03 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [4.0000000e+00 4.2400000e+02 8.1000000e+02 8.1000000e+02 8.4000000e+02\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4400000e+03 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4400000e+03\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [1.8700000e+02 6.5000000e+01 1.3500000e+03 1.3500000e+03 1.3800000e+03\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4400000e+03 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4400000e+03 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [3.0900000e+02 2.6800000e+02 1.0500000e+03 1.0500000e+03 1.1100000e+03\n",
            "  0.0000000e+00 1.4400000e+03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4400000e+03 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [3.3700000e+02 3.2500000e+02 1.1100000e+03 1.1100000e+03 1.1700000e+03\n",
            "  1.4400000e+03 1.4400000e+03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4400000e+03 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [1.8000000e+01 4.2200000e+02 1.1100000e+03 1.1100000e+03 1.1400000e+03\n",
            "  0.0000000e+00 1.4400000e+03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 1.4400000e+03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [1.6800000e+02 8.2000000e+01 9.0000000e+02 9.0000000e+02 9.6000000e+02\n",
            "  0.0000000e+00 0.0000000e+00 1.4400000e+03 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  1.4400000e+03 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [2.0100000e+02 1.0000000e+00 6.9000000e+02 6.9000000e+02 7.2000000e+02\n",
            "  0.0000000e+00 1.4400000e+03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4400000e+03 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [3.6100000e+02 3.5600000e+02 9.9000000e+02 9.9000000e+02 1.0200000e+03\n",
            "  0.0000000e+00 1.4400000e+03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4400000e+03\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [4.7900000e+02 2.7200000e+02 6.0000000e+02 6.0000000e+02 6.3000000e+02\n",
            "  1.4400000e+03 1.4400000e+03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 1.4400000e+03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n",
            "[[22.      ]\n",
            " [48.000004]\n",
            " [43.      ]\n",
            " [53.      ]\n",
            " [43.      ]\n",
            " [41.      ]\n",
            " [51.      ]\n",
            " [28.000002]\n",
            " [32.      ]\n",
            " [47.      ]]\n",
            "[[37.866825]\n",
            " [43.631195]\n",
            " [40.084766]\n",
            " [37.573265]\n",
            " [32.514423]\n",
            " [37.076477]\n",
            " [44.5463  ]\n",
            " [29.12203 ]\n",
            " [33.136803]\n",
            " [27.279203]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sg7Wx2zly2d",
        "colab_type": "text"
      },
      "source": [
        "# Resources & links\n",
        "\n",
        "https://medium.com/@benjamin.phillips22/simple-regression-with-neural-networks-in-pytorch-313f06910379\n",
        "\n",
        "https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/cifar10_tutorial.ipynb#scrollTo=RBCa4nG5wJAv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVQrueTnl43V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ggAdWToqPz6",
        "colab_type": "text"
      },
      "source": [
        "Problem: model guessing the same number for all inputs (mean/baseline)\n",
        "\n",
        "Solution: normalize input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh7BcvdCqZit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}